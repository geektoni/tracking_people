% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
\usepackage[strings]{underscore}
\usepackage{algorithm}
\usepackage{cite}
\usepackage{algpseudocode}

\renewcommand{\algorithmiccomment}[1]{// #1}

% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\usepackage[caption=false,font=normalsize,labelfon
t=sf,textfont=sf]{subfig}

\begin{document}
%
\title{Detecting and Tracking (People) Motion}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Giovanni De Toni (197184)\inst{1}}
%
%\authorrunning{F. Author et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{University of Trento, Italy, \email{giovanni.detoni@studenti.unitn.it}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
Detecting and tracking motion is one of the most common computer vision's tasks. Despite its apparent simplicity, this topic presents several tought spots and unexpected challenges which can be difficult to overcome. This work shows a simple and fast region-based approach to perform motion detection and subsequent tracking with a good grade of accuracy. Successively, a more advanced model based on the Kalman Filter is proposed in order to overcome some limitation of the first solution. These solutions are then tested on a pedestrian tracking task. Finally, we discuss the performance and the shortcomings of these two methods. 

\keywords{Tracking \and Detection  \and MOG \and Background Subtraction \and Kalman Filter \and OpenCV}
\end{abstract}
%
%
%
\section{Introduction}
Detection of moving objects and their subsequent tracking is a relatively easy task for humans. However, this operation becomes much more complicated when dealing with a computer video system. Recognize and follow passing objects by just looking at video recordings is incredibly useful for many real-world applications: surveillance systems, autonomous vehicles, crowds monitoring etc. The objective of this work is to produce a simple tracking system which is both accurate and with a relatively fast execution speed. Firstly, we tried to devise a procedure in order to detect motion in a reliable way, by applying background subtraction techniques. Secondly, we defined two methods to do dynamic tracking of detected objects by means of a region-based approach and of a more sophisticated solution which employ the Kalman filter.
This paper is structured in 4 main parts. Section 2 describes some related works on this topic and papers that were consulted for this work. Section 3 describes the chosen methods used to tackle the issue, from the objects detection (Mixture of Gaussians) to the tracking (region-based and Kalman-aided approaches). Section 4 describes the settings and results of the experiments done with our implementation. Finally, Section 5 elaborates the results of the experiments and we try to reach some conclusions.

\section{Related Works}
Firstly, we searched the literature in order to find suitable methods and techniques that are usually applied to these tasks.
Several papers regarding background subtraction for motion detection were published in previous years. Simple techniques such as frame differencing and adaptive background subtraction can be used if the scene presents fixed illumination and no background noise. Mixture of Gaussians (MOG) models are used in order to model complex, non-static backgrounds \cite{mog}. The MOG models went under extensive studies in order to increase their capabilities (for instance, \cite{mog_improved} shows how to extend them in order to do shadows detection). However, MOG still presents several shortcomings (sensible to the adaptation rate, performance depends on the number of Gaussians employed etc.) and therefore other more advanced methods were devised \cite{bg_codebook, bg_fuzzy, van2014vibe}. Shadows detection and removal was also a topic of several papers in which different techniques were proposed. For instance, HSV colour space conversion \cite{cucchiara2001detecting}, chromaticity and gradient correlation \cite{sanin2010detecting} etc.  
Object (people) tracking was discussed in many works. Many different methods are employed. From using Neural Networks to detect the human shape (or to generate crowd count from images)\cite{tang2017multiple, zhang2016single} to feature-based or region-based approaches \cite{5597093}. Researchers tried also to fuse together multiple algorithms in order to achieve stronger and more reliable predictors \cite{10.1007/3-540-47979-1_25}. Some papers discussed also how to recover from partial or total occlusions \cite{LERDSUDWICHAI20051059}.

\section{Methods}

The detection/tracking process was divided into several steps, each of them dealing with a specific issue/task. Moreover, the procedure was devised in order to use simple algorithms such that to provide a relatively easy-to-use system that requires a moderate computational power in order to be applied to real-time systems. The processing pipeline works as follow:
\begin{enumerate}
\item Shadow removal and Background Subtraction;
\item Feature extraction from the selected contours (centroids+histogram);
\item Prediction of their position/motion by using a region-based approach and a Kalman-aided approach;
\end{enumerate}
The implementation was done using C++ and the OpenCV library (release 2.4.13).

\subsection{Background Subtraction}
For each frame of the given video, the motion detection was performed using a Mixture of Gaussians technique described in the paper by Zivkovic \cite{Mog} in order to do background subtraction (this is implemented as \texttt{BackgroundSubtractorMOG2}\cite{backgroundsubtractormog} inside OpenCV). This technique was used in order to provide a more robust and precise detector. In fact, it can easily absorb eventual sudden changes in the environment (for instance, illumination variations). The result of this procedure is a greyscale image, in which the moving areas are displayed as white ``blobs" (Figure \ref{object_detection_result} shows the result of the entire processing pipeline on a video frame).
\smallskip

In order to avoid wrong motion detection caused by shadows cast by moving objects, each frame was also first converted from the RGB to the HSV space. Then, the hue (H) channel was extracted and the other components were discarded. This enabled us to remove eventual luminance variations which could have caused false positives.
This conversion proved itself to be most useful because it improved the quality of the motion detection. Figure \ref{object_detection} compares the result of this procedure when applying or not the HSV conversion.
The MOG method described in the paper is also able to detect shadows, which are highlighted in a different colour (a light grey). These were also removed by applying a binary thresholding. This shadow removal procedure produced a binary image in which the blobs are represented as white areas. 
Finally,  a sequence of opening and dilating operators with a rectangular shaped structuring element was then applied in order to remove the eventual noise, fill eventual holes and, more generally, to improve the blobs shapes.
\smallskip

\subsection{Contours Extaction}
As a second step, we applied a procedure to extract the contours from the binary frame containing the previously detected blobs (we used the OpenCV \texttt{findContours} \cite{findcontours} method). We filtered also the contours in order to reduce eventual noise by selecting only those which had an area above an empirical threshold. The threshold was selected in order to maximize the number of pedestrians found and to minimize the false positive (for instance, the detection of small parts of these pedestrians).  For each of these filtered contours, we generated also their corresponding bounding boxes.

We also recorded and provided the number of pedestrians detected for each frame of the video. 

\subsection{Region-Based People Tracking}

The object tracking was done using a region-based approach. Once detected in timestep t, the blobs detected on timestep t+1 are associated with the previous ones on thanks to the background subtraction, a proximity basis by also looking at the histogram information. More specifically, we check the distance between the blobs' centroids and the correlation coefficient of the histograms. Given two blobs, if those two metrics are below or above certain thresholds (again, the thresholds were chosen empirically by taking the ones which held the best results) then the blobs are considered to be the same and then they are associated. The association between the new blobs and the ``old" one is based on the best matching. The pedestrian that is closer to the newly detected blobs will win.After each association, each of the detected blobs' features is also updated (the new position is saved and a new histogram is computed) in order to account for possible small variations.

If we were not able to assign a specific blob to a previously detected human, it means that it could be a new pedestrian entering the scene. Therefore, we add it as a new human. To account for possible wrong detection, we start to track a newly detected blob only if it is closer to one of the borders of the scene frame (again, the distance has to be lower than a threshold). If a blob appears near one of the frame's border, we are reasonably sure that it is a new pedestrian entering the scene, while if it appears in the middle of the image, then it is unlikely to be a new human.

Moreover, if a pedestrian did not found any suitable next blob from the detected ones, it is marked as missing. If a tracked human stays missing for more than a certain amount of frames then it is considered to have exited the scene and it is not tracked anymore.

Algorithm \ref{tracking_algo} shows the general procedure. Note that the algorithm pseudocode presented here misses some small improvements or general logging facilities (like recording the trace for each tracked human for visualization purposes, etc.).
For more detailed informations please check the source code provided.

\subsection{Kalman-aided People Tracking}

Together with the simple solution described above, a more sophisticated method was tried in order to increase the quality of the tracking. The second approach consisted of using a Kalman filter (one personalized for each human detected) to predict the next position of the tracked pedestrian. The blob association procedure remained the same, but it was done against these new predicted positions, instead of the previous position. Once an association is made, the Kalman estimate is then corrected with the new ``measurement" and the pedestrian position is updated accordingly.


\section{Experiments}

\subsection{Settings}
Some experiments were conducted in order to find the best initialization parameters such that to have optimal detection and tracking capabilities. Table X shows the adopted configuration. 

The system used to run the experiments was an Ubuntu 16.04 virtual machine (it was executed through the Virtualbox appliance), with a single processor and 2 GB of RAM. The algorithm was also configured in order to do the tracking and detection for each frame of the video.

\begin{table}[h]
\centering
\caption{Final parameters for the algorithm}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|l|}
\hline
\textbf{Parameter} & \textbf{Description}                                                    & \textbf{Value} \\ \hline
\textit{t\_h}      & Threshold for the histogram correlation coefficient.                    & 0.5            \\
\textit{t\_e}      & Threshold for the euclidean distance difference between blobs.          & 40             \\
\textit{t\_b}      & Threshold for the border distance                                       & 30             \\
\textit{t\_d}      & Disappearence rate after which a human is not tracked anymore (frames). & 200            \\ \hline
\end{tabular}%
}
\label{table:params}
\end{table}

\subsection{Video Description}

The video which we used to run our experiments was a computer-generated simulation of pedestrians entering and exiting the scene acquired from top view. The video used MPEG-4 format and it had a frame size of 1280x720. The original colour space was the YUV. The size of the entire video was about 12 MB on disk with a duration of 50,876 seconds (all these information were extracted by using the \texttt{mediainfo} bash command).

All pedestrian moved in one direction only (without changing it) with almost constant velocity and the scene presented constant illumination. Apart from the pedestrian moving there was no other source of motion. 

\subsection{Results}
Generally, the entire procedure was relatively fast and was computationally efficient (we checked both CPU usage and memory consumption). The region-based approach was slightly faster than the Kalman-aided, but we noticed in both cases a minor slowdown when there were too many pedestrians on the scene. Figure X shows a sample frame of the video in which we see the tracking procedure working.

We also computed also the Root Mean Square Error (RMSE) for the people counting task. In the case of the tracking, we took three pedestrians (10,36 and 42) and we compared their recorded trace with the ground truth by computing for each frame the distance of each predicted trajectory point from the real ones. We then computed the mean and the standard deviation.

The algorithm was able to discover successfully most of the pedestrian crossing the scene, the RMSE of the detected pedestrian number with respect to the ground truth is around $3.94$. 
The tracking part gave instead very different results. The region-based approach performed well only in such situations in which the pedestrian is not occluded by too many other people. If that situation arises, then the trajectory is detected wrongly. Moreover, the performance over the detection of the selected pedestrians is somewhat poor. 
The Kalman-aided procedure worked instead much better. For instance, the tracking performance over the selected pedestrians outperforms the one obtained with only the region-based approach. Table X shows the final results.

\begin{table}[]
\centering
\caption{Mean and standard deviation of the detected trajectories with respect to the real ones.}
\label{table:disp}
\resizebox{0.5\textwidth}{!}{%
\begin{tabular}{|l|l|l|}
\hline
\textbf{Pedestrian Id} & \textbf{Region-Based} & \textbf{Kalman-aided} \\ \hline
\textit{10}            & $24.79\; \pm 12.06$                 & $25.51\; \pm 10.78$                 \\
\textit{36}            & $613.58\; \pm 399.51$                & $81.09\; \pm 103.69$                \\
\textit{42}            & $301.30\; \pm 320.88$                & $18.52\; \pm 12.45$                 \\ \hline
\end{tabular}%
}
\end{table}



\section{Conclusions}

The previous experiment showed us that we can easily build a detection/tracking system which can give us modest performances without employing cutting-edge hardware or software. However, our method presents several pitfalls which can be hardly solved completely. For instance, the background subtraction is not able to detect all the moving pedestrians and it suffers also of splitting events (in which a pedestrian is identified not as a complete entity, but maybe only by its torso and legs, which are two separate blobs). 
 The tracking part is the one which requires the most care. In fact, one issue of our proposed methods was that they cannot discriminate object in presence of occlusions. When two blobs merge together it becomes difficult to distinguish between them and to predict their next position, even if we consider the histogram information. One common solution to this problem is to avoid to update the model during occlusions. The objects positions are refreshed periodically only after a certain amount of frames. This will enable us to postpone the decision to a later frame when the blobs (hopefully) will have divided themselves.
The performance could be improved by using more sophisticated methods. 
By selecting other features rather than blob's centroids and histograms we may be able to improve the accuracy of the tracking phase. Template-based approaches could also be used, since if we wanted to track only human, then we would be better of by implementing a system which detects all the moving objects which have a ``human" shape.

%
% the environments 'definition', 'lemma', 'proposition', 'corollary',
% 'remark', and 'example' are defined in the LLNCS documentclass as well.
%
%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
% \bibliographystyle{splncs04}
% \bibliography{mybibliography}
%
\bibliographystyle{splncs04}
\bibliography{biblio}
%\begin{thebibliography}{8}



%\bibitem{ref_mog}
%Z. Zivkovic, Improved adaptive Gaussian mixture model for background subtraction, Proceedings of the 17th International %Conference on Pattern Recognition, 2004. ICPR 2004.
%vol. 2, 28-31 Vol.2, \doi{10.1109/ICPR.2004.1333992}

%\bibitem{ref_article1}
%Author, F.: Article title. Journal \textbf{2}(5), 99--110 (2016)

%\bibitem{ref_lncs1}
%Author, F., Author, S.: Title of a proceedings paper. In: Editor,
%F., Editor, S. (eds.) CONFERENCE 2016, LNCS, vol. 9999, pp. 1--13.
%Springer, Heidelberg (2016). \doi{10.10007/1234567890}

%\bibitem{ref_book1}
%Author, F., Author, S., Author, T.: Book title. 2nd edn. Publisher,
%Location (1999)

%\bibitem{ref_proc1}
%Author, A.-B.: Contribution title. In: 9th International Proceedings
%on Proceedings, pp. 1--2. Publisher, Location (2010)

%\bibitem{ref_url1}
%LNCS Homepage, \url{http://www.springer.com/lncs}. Last accessed 4
%Oct 2017
%\end{thebibliography}

\section*{Appendix}

\begin{figure}
\centering
\subfloat[Background subtraction without HSV shadow removal.]{\includegraphics[width=0.49\linewidth]{./images/shadows_300_no_removal.png}\label{tracknos}}
\hspace{0.01\linewidth}%
\subfloat[Background subtraction with HSV shadow removal.]{\includegraphics[width=0.49\linewidth]{./images/shadows_300.png}\label{tracks}}
\caption{Figure (a) shows the result of the background subtraction without the HSV conversion. We clearly see that the image
is more noisy and provide much more segmentation than Figure (b).}
\label{object_detection}
\end{figure}

\begin{figure}
%\subfloat[People detection without HSV shadow removal.]{\includegraphics[width=\linewidth]{./images/detection_300_no_removal.png}\label{detect_no_s}}
%\hfill
%\subfloat[People detection with HSV shadow removal]{}\label{detect_s}}
\includegraphics[width=\linewidth]{./images/detection_300.png}
\caption{This figure shows the results of the motion detection algorithm on a single frame of the video. Here the found contours (white) and bounding boxes (red) were applied to the original frame. On the top left corner, we can see the people counter.}
\label{object_detection_result}
\end{figure}

\begin{algorithm}
\caption{Track pedestrians given a set $C$ of contours (Simple solution)}
\label{tracking_algo}
\begin{algorithmic}[1]
\Require new detected contours $C$, previously detected pedestrians $P$, disappeared humans $D$
\If {$P.size() == 0$}
\State
\For{contour $c \in C$}
\State Create a new human $h$ with a new $id$
\State $h.position \gets c.centroid$
\State $h.histogram \gets c.histogram$
\State $h.disappeared = 0$
\State $P.push\_back(h)$
\EndFor
\Else
\State 
\For {contour $c \in C$}
\State $winner\_human \gets null$
\For {human $h \in P\backslash D$}
\State $h.disappeared \gets h.disappeared+1;$
\If {$correlation(h.histogram, c.histogram) > t\_h$}
\If {$e\_distance(h.position, c.centroid) < t\_e$}
\If {the new human $h$ is better than $winner\_human$}
\State $winner\_human \gets h$
\EndIf
\EndIf
\EndIf
\EndFor
\State 
\If {we found a human $h$ for the contour $c$}
\State $h.position \gets c.position $
\State $h.histogram \gets c.histogram$
\State $h.disappeared = 0$
\Else
\State $distance\_left \gets e\_distance(c.centroid, border\_left)$
\State $distance\_right \gets e\_distance(c.centroid, border\_right)$
\If {$ distance\_left < t\_b$ or $ distance\_right < t\_b$}
\State Create a new human $h$ with a new $id$
\State $h.position \gets c.centroid$
\State $h.histogram \gets c.histogram$
\State $h.disappeared \gets 0$
\State $P.push\_back(h)$
\EndIf
\EndIf
\EndFor
\State
\For {humans $h \in P\backslash D$}
\If {$h.disappeared \geq t\_d$}
\State $D.push\_back(h)$
\EndIf
\EndFor
\EndIf
\end{algorithmic}
\end{algorithm}

\begin{figure}
\includegraphics[width=\linewidth]{./images/tracking.png}
\caption{This figure shows the results of the motion detection algorithm on a single frame of the video. Here the found contours (white) and bounding boxes (red) were applied to the original frame. On the top left corner, we can see the people counter.}
\label{tracking}

\end{figure}
\end{document}
